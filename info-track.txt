- fixing issue: FastText recall is 'nan' but precision is a number. And the soltuion is pip3 install git+https://github.com/facebookresearch/fastText.git@b64e359d5485dda4b4b5074494155d18e25c8d13 
- fasttext model used to classifiy bug reports (security and non-security labels) [Done!]
- fasttext molde used to tagging the security reports with multiple labels [underprocess]
- Calcluate ROC and AUC [underprocess]
- writing the methodology section [ not schedule]
- on the virtual machine (virtualbox - ubunto) model = fasttext.train_supervised(input="ambari.valid") (not working)
model = fasttext.load_model("model_ambari.bin") (working good)
- Precision and Recall values Equals. This is because ""interpretation" of precision and recall in fastText", I am using binary classifications (security and non-security) while in fasttext apparently interprets any classification problem as multi-class.However, we are going to build our own confusion matrix.
    - useful links: https://github.com/facebookresearch/fastText/issues/93
    - soltuion for this issue: https://gist.github.com/loretoparisi/41b918add11893d761d0ec12a3a4e1aa#file-fasttext_confusion_matrix-py 